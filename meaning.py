import pandas as pd
import sqlite3
import google.generativeai as genai
import requests
import re
import os


genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
db_path = os.path.join(BASE_DIR, "data.db")
conn = sqlite3.connect(db_path)



def load_table_to_dict(table_name, value_column):
    df = pd.read_sql_query(f"SELECT WORD, {value_column} FROM {table_name}", conn)
    return dict(zip(df["WORD"].str.strip(), df[value_column]))

syn_dict = load_table_to_dict("synonyms", "SYNO_SET")
ant_dict = load_table_to_dict("antonyms", "ANTO_SET")
plur_dict = load_table_to_dict("plural", "PLURAL")



def lookup(word, type_):
    word = word.strip()
    
    if type_ == "synonyms":
        raw = syn_dict.get(word)
    elif type_ == "antonyms":
        raw = ant_dict.get(word)
    elif type_ == "plural":
        raw = plur_dict.get(word)
    else:
        return None

    if raw:
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØªÙ‚Ø³ÙŠÙ… Ø¹Ù„Ù‰ ;
        items = [item.strip() for item in raw.split(";") if item.strip()]
        return items if len(items) > 1 else items[0]
    return None


def clean_generated_result(text, type_):
    if not text:
        return None

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ§Ù„Ø³Ø·ÙˆØ± Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = text.strip()
    text = re.sub(r"[:Ø›ØŒ\"â€œâ€]", "", text)
    text = re.sub(r"\n.*", "", text)
    text = re.sub(r"\(.*?\)", "", text)
    text = re.sub(r"\[.*?\]", "", text)
    text = re.sub(r"\s+", " ", text).strip()

    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
    words = text.split()
    if len(words) > 3:
        return None

    return text



def generate_with_gemini(word, context, type_):
    prompt_map = {
        "synonyms": f"""Ø£Ø¹Ø·Ù Ù…Ø±Ø§Ø¯ÙÙ‹Ø§ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ØŒ Ø¨Ø´Ø±Ø· Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ø±Ø§Ø¯Ù Ù…Ø³Ø§ÙˆÙŠÙ‹Ø§ Ù„Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆÙ„ÙŠØ³ Ù‚Ø±ÙŠØ¨Ù‹Ø§ ÙÙ‚Ø·.
    ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø¥Ù† ÙˆÙØ¬Ø¯ØŒ ÙˆÙ„Ø§ ØªØ¹Ø·Ù Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù…Ø±Ø§Ø¯Ù ØµØ­ÙŠØ­ Ù„Ù„ÙƒÙ„Ù…Ø©ØŒ Ù‚Ù„ "Ù„Ø§ ÙŠÙˆØ¬Ø¯".""" ,
        
        "antonyms": f"""Ø£Ø¹Ø·Ù Ø¶Ø¯Ù‹Ø§ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ØŒ Ø¨Ø´Ø±Ø· Ø£Ù† ÙŠÙƒÙˆÙ† Ø¹ÙƒØ³Ù‹Ø§ Ù…Ø¨Ø§Ø´Ø±Ù‹Ø§ ÙˆØµØ­ÙŠØ­Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ø¹Ù†Ù‰.
    ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø¥Ù† ÙˆÙØ¬Ø¯ØŒ ÙˆÙ„Ø§ ØªØ¹Ø·Ù Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¶Ø¯ ØµØ­ÙŠØ­ Ù„Ù„ÙƒÙ„Ù…Ø©ØŒ Ù‚Ù„ "Ù„Ø§ ÙŠÙˆØ¬Ø¯".""" ,
    
        "plural": f"""Ø£Ø¹Ø·Ù Ø¬Ù…Ø¹Ù‹Ø§ ØµØ­ÙŠØ­Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.
    ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø¥Ù† ÙˆÙØ¬Ø¯ØŒ ÙˆÙ„Ø§ ØªØ¹Ø·Ù Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ù„ÙƒÙ„Ù…Ø© Ø¬Ù…Ø¹ Ù…Ø¹Ø±ÙˆÙØŒ Ù‚Ù„ "Ù„Ø§ ÙŠÙˆØ¬Ø¯".""" ,
    }

    prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„ØºÙˆÙŠ Ù…Ø­ØªØ±Ù ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
{prompt_map.get(type_, 'ÙØ³Ù‘Ø± Ø§Ù„ÙƒÙ„Ù…Ø©')} \n\n{context}"""

    try:
        response = model.generate_content(prompt)
        cleaned = clean_generated_result(response.text, type_)
        return cleaned
    except Exception as e:
        return f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {str(e)}"




def web_search_ai_agent(word, type_):
    print(f"ğŸ” Web searching for: {word} ({type_})")
    try:
        response = requests.post(
            "https://api.tavily.com/search",
            headers={"Authorization": f"Bearer {TAVILY_API_KEY}"},
            json={
                "query": f"Ù…Ø§ {type_} ÙƒÙ„Ù…Ø© {word}",
                "search_depth": "basic",
                "include_answer": False,
                "max_results": 3
            }
        )
        data = response.json()
        results = data.get("results", [])
        context = "\n".join([res["content"] for res in results])
        return generate_with_gemini(word, context, type_)
    except Exception as e:
        return f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: {str(e)}"



def ai_agent(word, type_):
    if len(word.strip().split()) > 1:
        return {"source": "validation", "result": "âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·."}
    
    local_result = lookup(word, type_)
    if local_result:
        return {"source": "lookup", "result": local_result}
    else:
        web_result = web_search_ai_agent(word, type_)
        return {"source": "web_search", "result": web_result}

